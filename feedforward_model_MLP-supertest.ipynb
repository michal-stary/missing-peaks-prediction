{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FF model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from prediction_utils import get_galaxy_filename\n",
    "\n",
    "base = \"../data\"\n",
    "dataset = \"nist\"\n",
    "kind = \"in_database\"\n",
    "\n",
    "\n",
    "wv_path = f\"gas2vec/{kind}.model\"\n",
    "\n",
    "data_train_path =f\"{base}/{dataset}/{kind}/train.msp\"\n",
    "data_val_path =f\"{base}/{dataset}/{kind}/val.msp\"\n",
    "data_test_path =f\"{base}/{dataset}/{kind}/test.msp\"\n",
    "\n",
    "data_realtest_path = get_galaxy_filename('RI using kovats of Mass spectra from RAMClustR', base, [\"enh\", \"pred\"])\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matchms.importing import load_from_msp\n",
    "\n",
    "from matchms.importing import load_from_msp\n",
    "from helpers import get_mz_vector, get_his_size\n",
    "from data_utils import spectrum_processing\n",
    "from data_utils import FixedSizeDS\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# only for visual \n",
    "from spec2vec import SpectrumDocument\n",
    "from data_utils import BasicCoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_process_documents(path):\n",
    "    # Load data from MSP file and apply filters\n",
    "    spectrums = [spectrum_processing(s, min_rel_int=None, n_required_peaks=1) for s in load_from_msp(path, metadata_harmonization=False)]\n",
    "    # Omit spectrums that didn't qualify for analysis\n",
    "    spectrums = [s for s in spectrums if s is not None]\n",
    "    # Create spectrum documents\n",
    "    documents = [SpectrumDocument(s, n_decimals=0) for s in spectrums]\n",
    "    return documents, spectrums\n",
    "\n",
    "# documents_train = load_process_documents(data_train_path)\n",
    "# documents_val = load_process_documents(data_val_path)\n",
    "# documents_test = load_process_documents(data_test_path)\n",
    "documents_supertest, spectrums_supertest = load_process_documents(data_realtest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = {\n",
    "    \"fixed_train\": FixedSizeDS(spectrums_supertest),\n",
    "    \"fixed_supertest\": FixedSizeDS(spectrums_supertest)\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"fixed_train\"][0][1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, max_mz=1001):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = max_mz\n",
    "        self.out_features = max_mz\n",
    "    \n",
    "        self.linear = nn.Linear(self.in_features, self.out_features)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return self.sigm(x)\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, max_mz=1001, hidden_layers=(2000,)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.in_features = max_mz\n",
    "        self.out_features = max_mz\n",
    "        \n",
    "        assert len(hidden_layers) != 0\n",
    "        self.relu = nn.ReLU()        \n",
    "        layers = [nn.Linear(self.in_features, hidden_layers[0])]\n",
    "        \n",
    "        for i in range(len(hidden_layers)-1):\n",
    "            layers.append(self.relu)\n",
    "            layers.append(nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n",
    "            \n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(hidden_layers[-1], self.out_features)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x= self.relu(x)\n",
    "        x = self.linear(x)\n",
    "        return self.sigm(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = Linear(datasets[\"fixed_train\"].max_mz)\n",
    "mlp_1 = MLP(datasets[\"fixed_train\"].max_mz, (1000,))\n",
    "mlp_2 = MLP(datasets[\"fixed_train\"].max_mz, (1000,1000))\n",
    "mlp_3 = MLP(datasets[\"fixed_train\"].max_mz, (1000,1000, 1000))\n",
    "mlp_1s = MLP(datasets[\"fixed_train\"].max_mz, (500,))\n",
    "mlp_2s = MLP(datasets[\"fixed_train\"].max_mz, (500,500))\n",
    "mlp_3s = MLP(datasets[\"fixed_train\"].max_mz, (500,500, 500))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# discver whether to use GPU or not\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorFF():\n",
    "    def __init__(self,model, max_mz=1001, threshold=.5):\n",
    "        self.model = model\n",
    "        self.max_mz= max_mz\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    @classmethod\n",
    "    def from_file(cls, file, device=\"cpu\", max_mz=1001, threshold=.5):\n",
    "        model = torch.load(file,  map_location=torch.device(device)) \n",
    "        return cls(model, max_mz=max_mz, threshold=threshold)\n",
    "   \n",
    "\n",
    "    def __call__(self, X):\n",
    "        with torch.no_grad():\n",
    "            return self.model(X)\n",
    "    \n",
    "    def predict_random_all(self, ds, probs, cum_level=.95, filtered=True, \\\n",
    "                           device=\"cpu\", **kwargs):\n",
    "        # reset rng before each prediction to have comparable results\n",
    "        self.rng = np.random.default_rng(42)\n",
    "\n",
    "        spectrums = ds.spectrums\n",
    "        m_pred_per_p = [[None for _ in range(len(spectrums))] for _ in range(len(probs))]\n",
    "        m_y_per_p = [[None for _ in range(len(spectrums))] for _ in range(len(probs))]\n",
    "        some_pred_per_p = [[None for _ in range(len(spectrums))] for _ in range(len(probs))]\n",
    "        \n",
    "        for i, spec in enumerate(spectrums):\n",
    "            vect = get_mz_vector(spec, self.max_mz)\n",
    "            \n",
    "            mat = np.zeros(shape=(len(probs),vect.shape[0]), dtype=np.float32)\n",
    "\n",
    "            # descending = np.argsort(spec.peaks.intensities)[::-1]\n",
    "            \n",
    "            # argsorted = np.argsort(vect)[::-1]\n",
    "            his_size = get_his_size(spec, cum_level)\n",
    "            his_ind = np.argpartition(vect, -his_size)[-his_size:]\n",
    "       \n",
    "            for m, p in enumerate(probs):\n",
    "                \n",
    "                ## cripple vector\n",
    "                mat[m] = vect.copy()\n",
    "                \n",
    "                # if too little peaks are present in the high intensity section, simply cut out top m most intense peaks \n",
    "                # cut_out_kths = self.rng.choice(max(n_peaks_considered, m), size=m, replace=False)\n",
    "                #cut_out_kths = self.rng.choice(n_peaks_considered, size=min(m, n_peaks_considered), replace=False)\n",
    "                \n",
    "                # his_ind = np.argsort(mat[m])[::-1][:his_size]\n",
    "                mask_missing = self.rng.uniform(0,1, self.max_mz) < p\n",
    "                \n",
    "                #cut_out_indices = argsorted[his_ind[mask_missing]] \n",
    "                \n",
    "                mat[m][mask_missing] = 0\n",
    "                \n",
    "                his_mask = np.zeros_like(vect) == 1\n",
    "                his_mask[his_ind] = True\n",
    "                \n",
    "                m_y_per_p[m][i] = np.where(mask_missing & his_mask)[0]\n",
    "                \n",
    "            # get predictions\n",
    "            with torch.no_grad():\n",
    "                mat_ = torch.from_numpy(mat).to(device)\n",
    "                pred = self.model(mat_)\n",
    "                pred = pred.cpu().numpy()    \n",
    "            \n",
    "            if filtered:\n",
    "                pred[mat!=0] = 0\n",
    "                \n",
    "            # get best peaks above threshold (except the given ones)    \n",
    "            for m in range(len(probs)):\n",
    "                some = np.where(pred[m] > self.threshold)[0]\n",
    "                some_pred_per_p[m][i] = some\n",
    "            \n",
    "            # get best m peaks (except the given ones)\n",
    "            for m in range(len(probs)):\n",
    "                next_m = np.argsort(pred[m])[::-1][:len(m_y_per_p[m][i])]\n",
    "                m_pred_per_p[m][i] = next_m     \n",
    "            \n",
    "        return some_pred_per_p, m_pred_per_p, m_y_per_p\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "done on the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_FOLDER = f\"predictions/{kind}\"\n",
    "probs = [0, .05, .1, .15, .2, .25, .3, .35, .4, .45, .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from metrics import metrics_klj, metrics_intlj\n",
    "\n",
    "predictors = { \n",
    "            \"linear_.8\": PredictorFF.from_file(f\"models/{kind}/linear\", max_mz=1001, device=device, threshold=.8),\n",
    "            \"linear_.5\": PredictorFF.from_file(f\"models/{kind}/linear\", max_mz=1001, device=device, threshold=.5),\n",
    "            \"linear_.3\": PredictorFF.from_file(f\"models/{kind}/linear\", max_mz=1001, device=device, threshold=.3),\n",
    "            \"linear_.1\": PredictorFF.from_file(f\"models/{kind}/linear\", max_mz=1001, device=device, threshold=.1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p_name=\"linear_3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_FOLDER = f\"predictions/{kind}\"\n",
    "probs = [0, .05, .1, .15, .2, .25, .3, .35, .4, .45, .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from metrics import metrics_klj, metrics_intlj\n",
    "\n",
    "predictors = { \n",
    "            \"mlp_1_.8\": PredictorFF.from_file(f\"models/{kind}/mlp_1\", max_mz=1001, device=device, threshold=.8),\n",
    "            \"mlp_1_.5\": PredictorFF.from_file(f\"models/{kind}/mlp_1\", max_mz=1001, device=device, threshold=.5),\n",
    "            \"mlp_1_.3\": PredictorFF.from_file(f\"models/{kind}/mlp_1\", max_mz=1001, device=device, threshold=.3),\n",
    "            \"mlp_1_.1\": PredictorFF.from_file(f\"models/{kind}/mlp_1\", max_mz=1001, device=device, threshold=.1),\n",
    "            \"mlp_2_.8\": PredictorFF.from_file(f\"models/{kind}/mlp_2\", max_mz=1001, device=device, threshold=.8),\n",
    "            \"mlp_2_.5\": PredictorFF.from_file(f\"models/{kind}/mlp_2\", max_mz=1001, device=device, threshold=.5),\n",
    "            \"mlp_2_.3\": PredictorFF.from_file(f\"models/{kind}/mlp_2\", max_mz=1001, device=device, threshold=.3),\n",
    "            \"mlp_2_.1\": PredictorFF.from_file(f\"models/{kind}/mlp_2\", max_mz=1001, device=device, threshold=.1),\n",
    "            \"mlp_3_.8\": PredictorFF.from_file(f\"models/{kind}/mlp_3\", max_mz=1001, device=device, threshold=.8),\n",
    "            \"mlp_3_.5\": PredictorFF.from_file(f\"models/{kind}/mlp_3\", max_mz=1001, device=device, threshold=.5),\n",
    "            \"mlp_3_.3\": PredictorFF.from_file(f\"models/{kind}/mlp_3\", max_mz=1001, device=device, threshold=.3),\n",
    "            \"mlp_3_.1\": PredictorFF.from_file(f\"models/{kind}/mlp_3\", max_mz=1001, device=device, threshold=.1),\n",
    "            \"mlp_2s_.8\": PredictorFF.from_file(f\"models/{kind}/mlp_2s\", max_mz=1001, device=device, threshold=.8),\n",
    "            \"mlp_2s_.5\": PredictorFF.from_file(f\"models/{kind}/mlp_2s\", max_mz=1001, device=device, threshold=.5),\n",
    "            \"mlp_2s_.3\": PredictorFF.from_file(f\"models/{kind}/mlp_2s\", max_mz=1001, device=device, threshold=.3),\n",
    "            \"mlp_2s_.1\": PredictorFF.from_file(f\"models/{kind}/mlp_2s\", max_mz=1001, device=device, threshold=.1)\n",
    "\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predictions/in_database'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p_name = \"mlp_2_.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supertest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets[\"fixed_supertest\"]\n",
    "batch_size = 1\n",
    "predictor = predictors[best_p_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_pred_per_p, _, _ = predictor.predict_random_all(ds,[0])\n",
    "preds = some_pred_per_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_utils import enhance_spectra, predict_spectra\n",
    "        \n",
    "enhanced_spectra = [*enhance_spectra(spectrums_supertest, preds, 5)]\n",
    "predicted_spectra = [*predict_spectra(spectrums_supertest, preds, 5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.exporting import save_as_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_msp(enhanced_spectra, f\"{data_realtest_path[:-4]}_enh_{best_p_name}.msp\")\n",
    "save_as_msp(predicted_spectra, f\"{data_realtest_path[:-4]}_pred_{best_p_name}.msp\")\n",
    "\n",
    "put(f\"{data_realtest_path[:-4]}_enh_{best_p_name}.msp\")\n",
    "put(f\"{data_realtest_path[:-4]}_pred_{best_p_name}.msp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([79]),\n",
       "  array([77]),\n",
       "  array([], dtype=int64),\n",
       "  array([ 81, 156, 226, 241]),\n",
       "  array([279]),\n",
       "  array([174]),\n",
       "  array([250]),\n",
       "  array([137, 140, 167, 203]),\n",
       "  array([191]),\n",
       "  array([221]),\n",
       "  array([], dtype=int64),\n",
       "  array([159, 242]),\n",
       "  array([229]),\n",
       "  array([], dtype=int64),\n",
       "  array([186, 187]),\n",
       "  array([], dtype=int64),\n",
       "  array([190]),\n",
       "  array([122, 158, 230]),\n",
       "  array([], dtype=int64),\n",
       "  array([181, 194, 197, 224, 226]),\n",
       "  array([159]),\n",
       "  array([104, 133, 257]),\n",
       "  array([105, 249]),\n",
       "  array([131]),\n",
       "  array([], dtype=int64),\n",
       "  array([219]),\n",
       "  array([328]),\n",
       "  array([165]),\n",
       "  array([157]),\n",
       "  array([315]),\n",
       "  array([], dtype=int64),\n",
       "  array([], dtype=int64),\n",
       "  array([], dtype=int64),\n",
       "  array([232]),\n",
       "  array([254, 312]),\n",
       "  array([296, 401]),\n",
       "  array([316]),\n",
       "  array([266, 286]),\n",
       "  array([155, 212, 223, 348]),\n",
       "  array([260]),\n",
       "  array([274]),\n",
       "  array([], dtype=int64),\n",
       "  array([133, 152, 212]),\n",
       "  array([ 90, 134]),\n",
       "  array([120]),\n",
       "  array([268]),\n",
       "  array([134, 292]),\n",
       "  array([218]),\n",
       "  array([104]),\n",
       "  array([], dtype=int64),\n",
       "  array([261, 328]),\n",
       "  array([201, 229, 255]),\n",
       "  array([332]),\n",
       "  array([], dtype=int64),\n",
       "  array([], dtype=int64),\n",
       "  array([], dtype=int64),\n",
       "  array([171]),\n",
       "  array([], dtype=int64),\n",
       "  array([203, 206, 275]),\n",
       "  array([320]),\n",
       "  array([306, 319]),\n",
       "  array([313, 343]),\n",
       "  array([195, 225, 246, 258]),\n",
       "  array([ 93, 105, 133, 161, 175, 215, 255, 327, 331]),\n",
       "  array([], dtype=int64),\n",
       "  array([77]),\n",
       "  array([ 77, 105, 181, 226, 227, 340]),\n",
       "  array([147, 327, 361])]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_pred_per_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_gen(ds, batch_size):\n",
    "    \n",
    "    for i in range((len(ds)//batch_size)):\n",
    "        n_sam = batch_size #if i*batch_size < len(ds) else len(ds) % batch_size\n",
    "        batch = torch.zeros(batch_size, 1001), torch.zeros(batch_size, 1001)\n",
    "        for j in range(n_sam):\n",
    "            batch[0][j] = ds[i*batch_size+j][0]\n",
    "            batch[1][j] = ds[i*batch_size+j][1]\n",
    "        yield batch\n",
    "            \n",
    "    n_sam = len(ds)% batch_size\n",
    "            \n",
    "    batch = torch.zeros(batch_size, 1001), torch.zeros(batch_size, 1001)    \n",
    "    for j in range((len(ds) % batch_size)):\n",
    "        batch[0][j] = ds[(i+1)*batch_size+j][0]\n",
    "        batch[1][j] = ds[(i+1)*batch_size+j][1]\n",
    "        yield batch\n",
    "            \n",
    "loader = loader_gen(ds, batch_size)\n",
    "len_loader = len(ds)//batch_size + 1\n",
    "\n",
    "\n",
    "X_intens = [np.sort(s.peaks.intensities)[::-1] for s in ds.spectrums]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PredictorFF' object has no attribute 'predict_l_next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-1a4b76a31aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     X_dict_batch = {\"input_ids\": torch.atleast_2d(X_dict_batch_[\"input_ids\"][X_dict_batch_[\"attention_mask\"] == 1])}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(X_dict_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_l_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dict_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#     pred = predictor.coder.index2mz[pred]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PredictorFF' object has no attribute 'predict_l_next'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "preds = []\n",
    "for b, X_dict_batch_ in enumerate(tqdm(loader)):\n",
    "    #print(X_dict_batch_)\n",
    "#     X_dict_batch = {\"input_ids\": torch.atleast_2d(X_dict_batch_[\"input_ids\"][X_dict_batch_[\"attention_mask\"] == 1])}\n",
    "    #print(X_dict_batch)\n",
    "    pred = predictor.predict_l_next(X_dict_batch, l=10)[0]\n",
    "#     pred = predictor.coder.index2mz[pred]\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugg_ds.ref_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrums_supertest[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrums_supertest[0].peaks.mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
