{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_utils import get_galaxy_filename\n",
    "\n",
    "base = \"../data\"\n",
    "dataset = \"nist\"\n",
    "kind = \"in_database\"\n",
    "\n",
    "\n",
    "wv_path = f\"gas2vec/{kind}.model\"\n",
    "\n",
    "data_train_path =f\"{base}/{dataset}/{kind}/train.msp\"\n",
    "data_val_path =f\"{base}/{dataset}/{kind}/val.msp\"\n",
    "data_test_path =f\"{base}/{dataset}/{kind}/test.msp\"\n",
    "\n",
    "data_realtest_path = get_galaxy_filename('RI using kovats of Mass spectra from RAMClustR', base, [\"enh\", \"pred\"])\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v = Word2Vec.load(wv_path)\n",
    "vocab = {e:i for i, e in enumerate(w2v.wv.index2entity)}\n",
    "#vocab[\"unknown\"] = -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.importing import load_from_msp\n",
    "from spec2vec import SpectrumDocument\n",
    "from data_utils import spectrum_processing\n",
    "from data_utils import IntegerMzCoder, TextMzCoder, TopKDS, GenDS, HuggDS\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_process_documents(path):\n",
    "    # Load data from MSP file and apply filters\n",
    "    spectrums = [spectrum_processing(s, min_rel_int=None, n_required_peaks=1) for s in load_from_msp(path, metadata_harmonization=False)]\n",
    "    # Omit spectrums that didn't qualify for analysis\n",
    "    spectrums = [s for s in spectrums if s is not None]\n",
    "    # Create spectrum documents\n",
    "    documents = [SpectrumDocument(s, n_decimals=0) for s in spectrums]\n",
    "    return documents, spectrums\n",
    "\n",
    "# documents_train = load_process_documents(data_train_path)\n",
    "# documents_val = load_process_documents(data_val_path)\n",
    "# documents_test = load_process_documents(data_test_path)\n",
    "documents_supertest, spectrums_supertest = load_process_documents(data_realtest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    # \"hugg_train\": HuggDS(documents_train, vocab, max_len=256), \n",
    "    # \"hugg_val\": HuggDS(documents_val, vocab, max_len=256), \n",
    "    # \"hugg_test\": HuggDS(documents_test, vocab, max_len=256),\n",
    "    \"hugg_supertest\": HuggDS(documents_supertest, vocab, max_len=256),\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    # \"train\": DataLoader(datasets[\"hugg_train\"], batch_size=64, shuffle=True, num_workers=8),\n",
    "    # \"val\": DataLoader(datasets[\"hugg_val\"], batch_size=256, shuffle=True, num_workers=8),\n",
    "    \"test\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "# Initializing a GPT2 configuration\n",
    "configuration = GPT2Config(n_positions=256, vocab_size=len(vocab)+1, \\\n",
    "                            bos_token_id=len(vocab), eos_token_id=len(vocab))#\\\n",
    "#                               pad_token_id=len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 1000,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 1000,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 256,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"transformers_version\": \"4.4.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 1001\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a model from the configuration\n",
    "gpt2 = GPT2LMHeadModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = gpt2.config\n",
    "\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.w2v = w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# discver whether to use GPU or not\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = gpt2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class PredictorDstGPT2():\n",
    "    def __init__(self, model, coder_class, max_mz=None):\n",
    "        self.model = model\n",
    "        self.coder = coder_class(model.w2v, max_mz)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, file, coder_cls, max_mz=None, device=\"cpu\"):\n",
    "        model = torch.load(file,  map_location=torch.device(device)) \n",
    "        return cls(model, coder_class=coder_cls, max_mz=max_mz)\n",
    "    \n",
    "    \n",
    "    def __call__(self, X_ds, device=\"cpu\"):\n",
    "        self.model= self.model.to(device)\n",
    "        X_ds = X_ds.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # return distribution for next peak \n",
    "            return F.softmax(self.model(**{\"input_ids\":X_ds}).logits[:, len(X_ds[0])-1],  dim=-1)\n",
    "    \n",
    "    def predict_l_next(self, X_dict_batch, l, filtered=True, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        receives indices and intens and predicts l next peaks\n",
    "        if filtered: returns only non-repetitive indices that are not given as input\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**X_dict_batch).logits[:, len(X_dict_batch[\"input_ids\"][0])-1]\n",
    "        \n",
    "        if filtered:\n",
    "            args_batch = torch.argsort(logits, dim=-1, descending=True).int().cpu()\n",
    "            res = torch.empty((len(X_dict_batch[\"input_ids\"]), l), dtype=torch.int)\n",
    "            for i in range(len(args_batch)):\n",
    "                given = set(X_dict_batch[\"input_ids\"][i])\n",
    "                solved = 0\n",
    "                for j in range(len(args_batch[0])):\n",
    "                    if args_batch[i][j] not in given:\n",
    "                        res[i][solved] = args_batch[i][j]\n",
    "                        solved +=1\n",
    "                    if solved == l:\n",
    "                        break\n",
    "                \n",
    "            return res.numpy()\n",
    "        \n",
    "        return torch.argsort(logits, dim=-1, descending=True)[:, :l].cpu().numpy()\n",
    "        \n",
    "\n",
    "    def predict_l_all(self, hugg_ds, up_to_k, l, batch_size=64, filtered=True, verbose=False, device=\"cpu\"):\n",
    "        \n",
    "        self.model= self.model.to(device)\n",
    "        \n",
    "        #loader = DataLoader(hugg_ds, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "        def loader_gen(ds, batch_size):\n",
    "            keys= ds[0].keys()\n",
    "            for i in range((len(ds)//batch_size)):\n",
    "                n_sam = batch_size #if i*batch_size < len(ds) else len(ds) % batch_size\n",
    "                batch = {k: torch.empty(n_sam, *v.shape, dtype=v.dtype) for k,v in ds[0].items()}\n",
    "                for j in range(n_sam):\n",
    "                    for key in keys:\n",
    "                        batch[key][j] = ds[i*batch_size+j][key]\n",
    "                yield batch\n",
    "            \n",
    "            n_sam = len(ds)% batch_size\n",
    "            \n",
    "            batch = {k: torch.empty(n_sam, *v.shape, dtype=v.dtype) for k,v in ds[0].items()}\n",
    "            for j in range(n_sam):\n",
    "                for key in keys:\n",
    "                    batch[key][j] = ds[(i+1)*batch_size+j][key]\n",
    "            yield batch\n",
    "        \n",
    "        loader = loader_gen(hugg_ds, batch_size)\n",
    "        len_loader = len(hugg_ds)//batch_size + 1\n",
    "\n",
    "        X_intens = [np.sort(doc.peaks.intensities)[::-1][:min(self.model.config.n_positions, len(doc.peaks.intensities))-1] for doc in hugg_ds.ref_docs]\n",
    "        \n",
    "        l_pred_indices_per_k = np.ones(shape=(up_to_k, len(hugg_ds), l)) * (-1)\n",
    "        y_indices = []\n",
    "        for b, X_dict_batch_ in enumerate(loader):\n",
    "                \n",
    "#             indices, intens = X_ds[:,0].numpy().astype(int), X_ds[:,1].numpy()\n",
    "            y_indices += [arr[(X_dict_batch_[\"attention_mask\"][u]==1).numpy()][1:] for u, arr in enumerate((X_dict_batch_[\"input_ids\"].numpy().astype(int)))]            \n",
    "    #             X_intens.append(intens)\n",
    "            for j in range(1, up_to_k+1):\n",
    "                # we skip evaluation for too short spectra\n",
    "#                 if j > len(indices):\n",
    "#                     continue\n",
    "               # print(j)\n",
    "                X_dict_batch = {\"input_ids\": X_dict_batch_[\"input_ids\"][:, :j].clone()}#{k: v.detach().clone() for k, v in X_dict_batch_.items()}\n",
    "                \n",
    "               # drop too short spectra\n",
    "                # get mask - for each sample in batch either True (long enough) or False (too short) \n",
    "                len_mask = X_dict_batch_[\"attention_mask\"][:, j-1] == 1\n",
    "                \n",
    "                X_dict_batch[\"input_ids\"] = X_dict_batch[\"input_ids\"][len_mask]\n",
    "\n",
    "                # no samples in batch left after cutting \n",
    "                if len_mask.sum() == 0:\n",
    "                    continue\n",
    "                X_dict_batch = {k: v.to(device) for k, v in X_dict_batch.items()}\n",
    "\n",
    "                l_next = self.predict_l_next(X_dict_batch, l, filtered, device=device)\n",
    "                \n",
    "                l_pred_indices_per_k[j-1,b*batch_size: (b+1)*(batch_size)][len_mask] = l_next\n",
    "            \n",
    "            if verbose and b % 1 == 0:\n",
    "                print(f\"Done: {b}/{len_loader}\")\n",
    "        return l_pred_indices_per_k, y_indices, X_intens \n",
    "\n",
    "\n",
    "class PredictorAutoGPT2():\n",
    "    def __init__(self, model, coder_class, max_mz=None):\n",
    "        self.model = model\n",
    "        self.coder = coder_class(model.w2v, max_mz)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, file, coder_cls, max_mz=None, device=\"cpu\"):\n",
    "        model = torch.load(file,  map_location=torch.device(device)) \n",
    "        return cls(model, coder_class=coder_cls, max_mz=max_mz)\n",
    "    \n",
    "    \n",
    "    def __call__(self, X_ds, device=\"cpu\"):\n",
    "        self.model= self.model.to(device)\n",
    "        X_ds = X_ds.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # return distribution for next peak \n",
    "            return F.softmax(self.model(**{\"input_ids\":X_ds}).logits[:, len(X_ds[0])-1], dim=-1)\n",
    "    \n",
    "    def predict_l_next(self, X_dict_batch, l, filtered=True, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        receives indices and intens and predicts l next peaks\n",
    "        if filtered: returns only non-repetitive indices that are not given as input\n",
    "        \"\"\"\n",
    "        \n",
    "        k = X_dict_batch[\"input_ids\"].shape[1]\n",
    "\n",
    "        if filtered:\n",
    "            return self.model.generate(\n",
    "                X_dict_batch[\"input_ids\"], \n",
    "                max_length=k+l, \n",
    "                #num_beams=5, \n",
    "                no_repeat_ngram_size=1, \n",
    "                #encoder_no_repeat_ngram_size=1,\n",
    "                #early_stopping=True, \n",
    "                #bad_words_ids = X_dict_batch[\"input_ids\"].tolist(),\n",
    "                pad_token_id=len(self.coder.vocab)\n",
    "            ).cpu().numpy()[:, k:]\n",
    "\n",
    "#             res = torch.empty(len(X_dict_batch[\"input_ids\"]), l, dtype=torch.int) \n",
    "#             for i in range(len(beam_output)):\n",
    "#                 uniq_row = torch.unique(beam_output[i])\n",
    "#                 assert len(uniq_row) >= l \n",
    "#                 res[i, :] = uniq_row[:l]\n",
    "#             return res\n",
    "            \n",
    "        \n",
    "        return self.model.generate(\n",
    "                X_dict_batch[\"input_ids\"], \n",
    "                max_length=k+l, \n",
    "                #num_beams=5, \n",
    "                #early_stopping=True, \n",
    "                pad_token_id=len(self.coder.vocab)\n",
    "        ).cpu().numpy()[:, k:]\n",
    "        \n",
    "#       \n",
    "    def predict_l_all(self, hugg_ds, up_to_k, l, batch_size=64, filtered=True, verbose=False, device=\"cpu\"):\n",
    "        self.model= self.model.to(device)\n",
    "        \n",
    "        #loader = DataLoader(hugg_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        def loader_gen(ds, batch_size):\n",
    "            keys= ds[0].keys()\n",
    "            for i in range((len(ds)//batch_size)):\n",
    "                n_sam = batch_size #if i*batch_size < len(ds) else len(ds) % batch_size\n",
    "                batch = {k: torch.empty(n_sam, *v.shape, dtype=v.dtype) for k,v in ds[0].items()}\n",
    "                for j in range(n_sam):\n",
    "                    for key in keys:\n",
    "                        batch[key][j] = ds[i*batch_size+j][key]\n",
    "                yield batch\n",
    "            \n",
    "            n_sam = len(ds)% batch_size\n",
    "            \n",
    "            batch = {k: torch.empty(n_sam, *v.shape, dtype=v.dtype) for k,v in ds[0].items()}\n",
    "            for j in range(n_sam):\n",
    "                for key in keys:\n",
    "                    batch[key][j] = ds[(i+1)*batch_size+j][key]\n",
    "            yield batch\n",
    "            \n",
    "        loader = loader_gen(hugg_ds, batch_size)\n",
    "        len_loader = len(hugg_ds)//batch_size + 1\n",
    "        X_intens = [np.sort(doc.peaks.intensities)[::-1][:min(self.model.config.n_positions, len(doc.peaks.intensities))-1] for doc in hugg_ds.ref_docs]\n",
    "\n",
    "        \n",
    "        l_pred_indices_per_k = np.ones(shape=(up_to_k, len(hugg_ds), l)) * (-1)\n",
    "        y_indices = []\n",
    "\n",
    "        for b, X_dict_batch_ in enumerate(loader):\n",
    "                \n",
    "#             indices, intens = X_ds[:,0].numpy().astype(int), X_ds[:,1].numpy()\n",
    "            y_indices += [arr[(X_dict_batch_[\"attention_mask\"][u]==1).numpy()][1:] for u, arr in enumerate((X_dict_batch_[\"input_ids\"].numpy().astype(int)))]\n",
    "#             X_intens.append(intens)\n",
    "            for j in range(1, up_to_k+1):\n",
    "                # we skip evaluation for too short spectra\n",
    "#                 if j > len(indices):\n",
    "#                     continue\n",
    "               # print(j)\n",
    "                X_dict_batch = {\"input_ids\": X_dict_batch_[\"input_ids\"][:, :j].clone()}#{k: v.detach().clone() for k, v in X_dict_batch_.items()}\n",
    "                \n",
    "                # drop too short spectra\n",
    "                # get mask - for each sample in batch either True (long enough) or False (too short) \n",
    "                len_mask = X_dict_batch_[\"attention_mask\"][:, j-1] == 1\n",
    "                \n",
    "                X_dict_batch[\"input_ids\"] = X_dict_batch[\"input_ids\"][len_mask]\n",
    "\n",
    "                # no samples in batch left after cutting \n",
    "                if len_mask.sum() == 0:\n",
    "                    continue\n",
    "                X_dict_batch = {k: v.to(device) for k, v in X_dict_batch.items()}\n",
    "\n",
    "                l_next = self.predict_l_next(X_dict_batch, l, filtered, device=device)\n",
    "                \n",
    "                l_pred_indices_per_k[j-1,b*batch_size: (b+1)*(batch_size)][len_mask] = l_next\n",
    "            \n",
    "            if verbose and b % 1 == 0:\n",
    "                print(f\"Done: {b}/{len_loader}\")\n",
    "        return l_pred_indices_per_k, y_indices, X_intens "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "done on the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from metrics import metrics_klj, metrics_intlj\n",
    "\n",
    "predictors = { \n",
    "            \"gpt2_first_dst\": PredictorDstGPT2.from_file(f\"models/{kind}/gpt2\", TextMzCoder, max_mz=None, device=device),\n",
    "            \"gpt2_ns_dst\": PredictorDstGPT2.from_file(f\"models/{kind}/gpt2_lr5e-5_ns\", TextMzCoder, max_mz=None, device=device),  \n",
    "            \"gpt2_dst\": PredictorDstGPT2.from_file(f\"models/{kind}/gpt2_lr5e-5\", TextMzCoder, max_mz=None, device=device),  \n",
    "            \"gpt2_first_auto\": PredictorAutoGPT2.from_file(f\"models/{kind}/gpt2\", TextMzCoder, max_mz=None, device=device),\n",
    "            \"gpt2_auto\": PredictorAutoGPT2.from_file(f\"models/{kind}/gpt2_lr5e-5\", TextMzCoder, max_mz=None, device=device),\n",
    "            \"gpt2_ns_auto\": PredictorAutoGPT2.from_file(f\"models/{kind}/gpt2_lr5e-5_ns\", TextMzCoder, max_mz=None, device=device),\n",
    "                \n",
    "             }\n",
    "\n",
    "P_FOLDER = f\"predictions/{kind}\"\n",
    "up_to_k = 30\n",
    "l = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p_name = \"gpt2_ns_auto\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supertest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugg_ds = datasets[\"hugg_supertest\"]\n",
    "batch_size = 1\n",
    "predictor = predictors[best_p_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_utils.HuggDS at 0x7fa15a1b19e8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loader_gen(ds, batch_size):\n",
    "    keys= ds[0].keys()\n",
    "    for i in range((len(ds)//batch_size)):\n",
    "        n_sam = batch_size #if i*batch_size < len(ds) else len(ds) % batch_size\n",
    "        batch = {k: torch.empty(n_sam, *v.shape, dtype=v.dtype) for k,v in ds[0].items()}\n",
    "        for j in range(n_sam):\n",
    "            for key in keys:\n",
    "                batch[key][j] = ds[i*batch_size+j][key]\n",
    "        yield batch\n",
    "            \n",
    "    n_sam = len(ds)% batch_size\n",
    "            \n",
    "    batch = {k: torch.empty(n_sam, *v.shape, dtype=v.dtype) for k,v in ds[0].items()}\n",
    "    for j in range((len(ds)%batch_size)):\n",
    "        for key in keys:\n",
    "            batch[key][j] = ds[(i+1)*batch_size+j][key]\n",
    "        yield batch\n",
    "            \n",
    "loader = loader_gen(hugg_ds, batch_size)\n",
    "len_loader = len(hugg_ds)//batch_size + 1\n",
    "X_intens = [np.sort(doc.peaks.intensities)[::-1][:min(predictor.model.config.n_positions, len(doc.peaks.intensities))-1] for doc in hugg_ds.ref_docs]\n",
    "\n",
    "datasets[\"hugg_supertest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.coder.vocab[\"peak@115\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hugg_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-21-b0d6ff68a30d>\", line 7, in <module>\n",
      "    pred = predictor.predict_l_next(X_dict_batch, l=10)[0]\n",
      "  File \"<ipython-input-14-6a011ba71aba>\", line 147, in predict_l_next\n",
      "    pad_token_id=len(self.coder.vocab)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/generation_utils.py\", line 991, in generate\n",
      "    **model_kwargs,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/generation_utils.py\", line 1265, in greedy_search\n",
      "    output_hidden_states=output_hidden_states,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 917, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 760, in forward\n",
      "    output_attentions=output_attentions,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 321, in forward\n",
      "    feed_forward_hidden_states = self.mlp(self.ln_2(hidden_states))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 261, in forward\n",
      "    h = self.act(self.c_fc(x))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\", line 1224, in forward\n",
      "    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 173, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "preds = []\n",
    "for b, X_dict_batch_ in enumerate(tqdm(loader)):\n",
    "    #print(X_dict_batch_)\n",
    "    X_dict_batch = {\"input_ids\": torch.atleast_2d(X_dict_batch_[\"input_ids\"][X_dict_batch_[\"attention_mask\"] == 1])}\n",
    "    #print(X_dict_batch)\n",
    "    pred = predictor.predict_l_next(X_dict_batch, l=10)[0]\n",
    "    pred = predictor.coder.index2mz[pred]\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spec2vec.SpectrumDocument.SpectrumDocument at 0x7fb3ef8d78d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hugg_ds.ref_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ionmode': 'Negative',\n",
       " 'spectrumtype': 'Centroid',\n",
       " 'num_peaks': '19',\n",
       " 'compound_name': 'C11',\n",
       " 'retention_time': '122.61',\n",
       " 'retention_index': '1085.917874'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrums_supertest[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72.05694212,  73.06470108,  76.0181442 ,  78.01498857,\n",
       "        80.03861506,  86.06807381,  86.07251984, 100.08824961,\n",
       "       114.09945172, 120.08875599, 127.11156231, 176.06747288,\n",
       "       302.12101639])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrums_supertest[0].peaks.mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_utils import enhance_spectra, predict_spectra\n",
    "        \n",
    "enhanced_spectra = [*enhance_spectra(spectrums_supertest, preds, 5)]\n",
    "predicted_spectra = [*predict_spectra(spectrums_supertest, preds, 5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.exporting import save_as_msp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_msp(enhanced_spectra, f\"{data_realtest_path[:-4]}_enh_GPT2_5.msp\")\n",
    "save_as_msp(predicted_spectra, f\"{data_realtest_path[:-4]}_pred_GPT2_5.msp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "put(f\"{data_realtest_path[:-4]}_enh_GPT2_5.msp\")\n",
    "put(f\"{data_realtest_path[:-4]}_pred_GPT2_5.msp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
